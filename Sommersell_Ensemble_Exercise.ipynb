{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osommersell264/MLsessions/blob/main/Sommersell_Ensemble_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Task: Create an Ensemble\n",
        "\n"
      ],
      "metadata": {
        "id": "0MhB7souuE8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the data"
      ],
      "metadata": {
        "id": "q5hWeXbc2eK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo\n",
        "from ucimlrepo import fetch_ucirepo"
      ],
      "metadata": {
        "id": "TL-Z4gGctdTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f13bc97-f73c-4c4c-bd22-a5cb1b68e3f2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some useful imports - feel free to modify\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n"
      ],
      "metadata": {
        "id": "PjcQo0CqxqVK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch dataset\n",
        "predict_students_dropout_and_academic_success = fetch_ucirepo(id=697)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = predict_students_dropout_and_academic_success.data.features\n",
        "y = predict_students_dropout_and_academic_success.data.targets\n",
        "\n",
        "# Drop enrolled\n",
        "X = X[y != 'Enrolled']\n",
        "y = y[y != 'Enrolled']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "# Why Big X and little y?\n",
        "# X represents the matrix of x features, y represents the vector of y outcome."
      ],
      "metadata": {
        "id": "EYQXaH6itafW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Calculate Base-Rate Accuracy (Naive Model)\n",
        "base_rate_accuracy = y.value_counts().max() / len(y)\n",
        "print(f\"Base-Rate Accuracy (Naive Model): {base_rate_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "CYFO0TWc-0Qp",
        "outputId": "2a77ebb4-086f-44e0-82b5-5eda4bf520d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-5-5bbfcd1fa78f>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-5bbfcd1fa78f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Calculate Base-Rate Accuracy (Naive Model)\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vWAIuxVUx-on"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a few classifiers classifiers\n",
        "- you don't need to fit or predict here, just initialize the model\n"
      ],
      "metadata": {
        "id": "x0Rxs5oOxEhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a few classifiers classifiers\n",
        "modelA = DecisionTreeClassifier(max_depth=5, random_state=42)  # Simple decision tree\n",
        "modelB = LogisticRegression(max_iter=1000, random_state=42)    # Logistic regression for binary classification\n",
        "modelC = RandomForestClassifier(n_estimators=100, random_state=42)  # More complex decision trees combined"
      ],
      "metadata": {
        "id": "bX2WIycIyiLc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleaning & Preprocessing\n",
        "# Convert target variable to binary format: Graduate = 1, Dropout = 0\n",
        "y = y.map({\"Graduate\": 1, \"Dropout\": 0})"
      ],
      "metadata": {
        "id": "t0txQ0X2_PoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical variables to numerical values\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    X[col] = LabelEncoder().fit_transform(X[col])"
      ],
      "metadata": {
        "id": "JP4Jrm6G_PX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize numerical features to improve model performance\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "tj9vUMBi_PJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train-Test Split\n",
        "# We split the dataset into 80% training and 20% testing to evaluate model performance.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "pzVQNEd7_bya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z4-ulyIo_bh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create an Ensemble"
      ],
      "metadata": {
        "id": "hrCgs6aiypPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Create the Ensemble Model\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('decision_tree', modelA),\n",
        "        ('logistic_regression', modelB),\n",
        "        ('random_forest', modelC)\n",
        "    ],\n",
        "    voting='soft'  # Changed to soft voting for better probability distribution\n",
        ")\n",
        "\n",
        "\n",
        "# Train you ensemble (hint use `.fit()`)\n",
        "ensemble.fit(X_train, y_train)\n",
        "\n",
        "# Create predictions (hint use `.predict()`)\n",
        "y_pred_ensemble = ensemble.predict(X_test)"
      ],
      "metadata": {
        "id": "5RFrV7VOx33n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the Ensemble Model\n",
        "ensemble_accuracy = accuracy_score(y_test, y_pred_ensemble)\n",
        "print(f\"Ensemble Model Accuracy: {ensemble_accuracy:.2f}\")\n",
        "print(\"Ensemble Classification Report:\\n\", classification_report(y_test, y_pred_ensemble))\n",
        "\n",
        "#Feature Importance Analysis (Random Forest)\n",
        "feature_importances = pd.Series(modelC.feature_importances_, index=X.columns)\n",
        "print(\"Feature Importances (Random Forest):\\n\", feature_importances.sort_values(ascending=False))\n"
      ],
      "metadata": {
        "id": "10D0AFi2_xUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare with Individual Models\n",
        "modelA.fit(X_train, y_train)\n",
        "y_pred_dt = modelA.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
        "print(f\"Decision Tree Accuracy: {dt_accuracy:.2f}\")\n",
        "\n",
        "modelB.fit(X_train, y_train)\n",
        "y_pred_lr = modelB.predict(X_test)\n",
        "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
        "print(f\"Logistic Regression Accuracy: {lr_accuracy:.2f}\")\n",
        "\n",
        "modelC.fit(X_train, y_train)\n",
        "y_pred_rf = modelC.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "HF1Ujyrm_xPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12: Visualizing Confusion Matrices\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_ensemble), annot=True, fmt='d', cmap='Reds', ax=axes[0, 0])\n",
        "axes[0, 0].set_title('Ensemble Model')\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_dt), annot=True, fmt='d', cmap='Blues', ax=axes[0, 1])\n",
        "axes[0, 1].set_title('Decision Tree')\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_lr), annot=True, fmt='d', cmap='Greens', ax=axes[1, 0])\n",
        "axes[1, 0].set_title('Logistic Regression')\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Oranges', ax=axes[1, 1])\n",
        "axes[1, 1].set_title('Random Forest')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VmeHm5uq_xLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hivLwecG_xHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ptk_sOmx_xDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lAbxOaV4_w-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VwyrWTco_w6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_aqvfm1W_wu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy metrics\n",
        "# how are FP/FN different between your models, what balance is the ensemble striking?"
      ],
      "metadata": {
        "id": "adMktkN5yn0z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}